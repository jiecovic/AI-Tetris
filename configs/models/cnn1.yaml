# @package _group_
policy_kwargs:
  net_arch: []
  activation_fn: GELU   # or whatever mapping you use


feature_extractor:


  spatial_preprocessor:
    type: binary                 # options: binary (later RGB)
    params: {}                   # binary: no params

  stem:
    type: conv3x3_32_32_64                     # options: none | cnn | conv3x3_32_32_64
#      params: { }                     # none: no stem applied

    # ------------------------------------------------------------------
    # if type: conv3x3_32_32_64 (fixed preset, no tuning knobs)
    # ------------------------------------------------------------------
    # params: {}                   # preset-defined architecture

    # ------------------------------------------------------------------
    # if type: cnn (generic configurable CNN stem)
    # ------------------------------------------------------------------
    # params:
    #   channels: [32, 32, 64]     # options: list[int], out_channels per conv layer
    #   kernel_size: 3             # options: int > 0 (usually 3)
    #   stride: 1                  # options: int > 0
    #   padding: same              # options: valid | same | tetris
    #   activation: relu           # options: relu | gelu | identity
    #   dropout: 0.0               # options: float >= 0
    #   use_batchnorm: false       # options: true | false (NOT RL-friendly)


  encoder:
    type: spatial  # token | spatial

    # ------------------------------------------------------------------
    # token encoder (used when type: token)
    # ------------------------------------------------------------------

    spatial_head:
      type: col_collapse        # options: global_pool | flatten | col_collapse | attn_pool
      params:
        features_dim: 512          # base encoder output dim (B, F_base)
        collapse: linear
        pool: avgmax          # options: mean | max | meanmax (if applicable)
        use_batchnorm: false
        include_active_onehot: true
        include_next_onehot: true
        dropout: 0.0

  feature_augmenter:
    type: null               # options: null | onehot_concat | mlp_joint | mlp_split
#      params:
#        use_active: true        # include one-hot of active piece kind
#        use_next: true          # include one-hot(s) of next queue
#


