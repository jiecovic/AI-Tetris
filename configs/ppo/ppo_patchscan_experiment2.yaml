# @package _global_
defaults:
  - /hydra: default
  - /envs@env_train: warmup_finite_horizon
  - /rewards@env_train.reward: lines_height_scaled_terminal
  - /envs@env_eval: empty
  - /rewards@env_eval.reward: lines_height_scaled_terminal
  - /sb3_policies@policy: patchscan_experiment1
  - /trains@_global_: ppo_eval
  - _self_

log_level: info                      # logging verbosity

run:
  name: ppo_patchscan_experiment2_run   # run name (used for output dir)
  seed: 0                            # base RNG seed
  out_root: runs                     # output root directory
  tensorboard: true                  # enable TensorBoard logging
  device: cuda                       # cuda | cpu | auto
  n_envs: 64                         # fewer envs for faster iteration
  vec: dummy                         # subproc | dummy
